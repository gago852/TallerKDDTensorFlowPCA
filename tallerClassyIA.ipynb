{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('python37': conda)",
   "display_name": "Python 3.7.9 64-bit ('python37': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dafc5c0e3e943e29bb3c54d62d3dddf716691f4959a81fc76b2d95fe45096a74"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#integrantes: GABRIEL GOMEZ, EDUARDO DE LA HOZ, STEPHANIA DE LA HOZ, NEMESYS EVILLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(df,k):\n",
    "    return df[(abs(df[0]-np.mean(df[0])) <= k*np.std(df[0])) & (abs(df[1]-np.mean(df[1])) <= k*np.std(df[1])) & (abs(df[2]-np.mean(df[2])) <= k*np.std(df[2])) & (abs(df[3]-np.mean(df[3])) <= k*np.std(df[3]))]\n",
    "def skynet(patrones,objetivos):\n",
    "    patron=patrones.to_numpy()\n",
    "    objetivo=objetivos.to_numpy()\n",
    "    modelo=Sequential()\n",
    "    modelo.add(Dense(10,input_dim=2, activation='sigmoid'))\n",
    "    modelo.add(Dense(1, activation='linear'))\n",
    "    modelo.compile(loss='mean_squared_error', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    modelo.fit(patron,objetivo,epochs=1000,verbose=0)\n",
    "    puntaje= modelo.evaluate(patron,objetivo)\n",
    "    print(\"\\n%s: %.2f%%\" % (modelo.metrics_names[1], puntaje[1]*100))\n",
    "    return modelo\n",
    "def prueba(modelo,dfPrueba):\n",
    "    conjuntoPrueba=dfPrueba.to_numpy()\n",
    "    preduccion=modelo.predict(conjuntoPrueba)\n",
    "    return preduccion\n",
    "def atinar(dataframe):\n",
    "    datos=pd.DataFrame(data=np.zeros(len(dataframe)),columns=['resultado'],index=dataframe.index)\n",
    "    datos['acierto']=(1==1)\n",
    "    for row in dataframe.iterrows():\n",
    "        if row[1]['prediccion'] <0.3:\n",
    "            datos.at[row[0],'resultado']=0\n",
    "        elif row[1]['prediccion'] >= 0.3 and row[1]['prediccion'] <0.7:\n",
    "            datos.at[row[0],'resultado']=0.5\n",
    "        elif row[1]['prediccion'] >= 0.7:\n",
    "            datos.at[row[0],'resultado']=1\n",
    "        else:\n",
    "            datos.at[row[0],'resultado']=-1\n",
    "    datos['acierto']=np.where(datos['resultado']==dataframe[2],True,False)\n",
    "    dataframe['resultado']=datos['resultado']\n",
    "    dataframe['resultado']=datos['resultado'].values\n",
    "    dataframe['acierto']=datos['acierto']\n",
    "    dataframe['acierto']=datos['acierto'].values\n",
    "    return dataframe\n",
    "def confusio(data):\n",
    "    act=pd.Series(data['resultado'], name='actual')\n",
    "    pred=pd.Series(data[2], name='predicho')\n",
    "    matriz=pd.crosstab(act,pred)\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_table('irisdata.txt',skiprows=9,header=None)\n",
    "dfClean=df.copy()\n",
    "cat=df.iloc[:,4]\n",
    "catn=cat.replace([1,2],[0.5,1])\n",
    "catn=np.array(catn)\n",
    "df=df.drop(columns=4)\n",
    "rawdata=np.array(df)\n",
    "covRawData = np.cov(rawdata.T)\n",
    "resultRaw = la.eig(covRawData)\n",
    "eugenVector=resultRaw[1]\n",
    "eugenValors=resultRaw[0].real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio=np.mean(rawdata)\n",
    "x=rawdata-promedio\n",
    "proyeccion= eugenVector.T[:][:2].T\n",
    "xPC=x.dot(proyeccion)\n",
    "dfFlores=pd.DataFrame(data=xPC)\n",
    "dfFlores[2]=catn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = 0.80 # Porcentaje de train.\n",
    "\n",
    "dfFlores['entrenamiento'] = np.random.uniform(0, 1, len(dfFlores)) <= p_train\n",
    "train, test = dfFlores[dfFlores['entrenamiento']==True], dfFlores[dfFlores['entrenamiento']==False]\n",
    "dfFlores = dfFlores.drop('entrenamiento', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=0.50\n",
    "train['entrenamiento']=np.random.uniform(0,1,len(train)) <=algo\n",
    "mitad1, mitad2= train[train['entrenamiento']==True], train[train['entrenamiento']==False]\n",
    "\n",
    "mitad1['entrenamiento']=np.random.uniform(0,1,len(mitad1)) <=algo\n",
    "mitad2['entrenamiento']=np.random.uniform(0,1,len(mitad2)) <=algo\n",
    "\n",
    "df1, df2,df3,df4= mitad1[mitad1['entrenamiento']==True], mitad1[mitad1['entrenamiento']==False],mitad2[mitad2['entrenamiento']==True], mitad2[mitad2['entrenamiento']==False]\n",
    "\n",
    "df1=df1.drop('entrenamiento',1)\n",
    "df2=df2.drop('entrenamiento',1)\n",
    "df3=df3.drop('entrenamiento',1)\n",
    "df4=df4.drop('entrenamiento',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entreno1=df2.append([df3,df4])\n",
    "entreno2=df1.append([df3,df4])\n",
    "entreno3=df1.append([df2,df4])\n",
    "entreno4=df1.append([df2,df3])\n",
    "\n",
    "modelo1=skynet(entreno1.drop(2,1),entreno1[2])\n",
    "modelo2=skynet(entreno2.drop(2,1),entreno2[2])\n",
    "modelo3=skynet(entreno3.drop(2,1),entreno3[2])\n",
    "modelo4=skynet(entreno4.drop(2,1),entreno4[2])\n",
    "\n",
    "prediccion1=prueba(modelo1,df1.drop(2,1))\n",
    "prediccion2=prueba(modelo2,df2.drop(2,1))\n",
    "prediccion3=prueba(modelo3,df3.drop(2,1))\n",
    "prediccion4=prueba(modelo4,df4.drop(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=train.drop('entrenamiento',1)\n",
    "test=test.drop('entrenamiento',1)\n",
    "\n",
    "modeloTotal=skynet(train.drop(2,1),train[2])\n",
    "\n",
    "prediccionTotal=prueba(modeloTotal,test.drop(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediccionTotal.round(2))\n",
    "print(prediccion1.round(2))\n",
    "print(prediccion2.round(2))\n",
    "print(prediccion3.round(2))\n",
    "print(prediccion4.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediccion']=prediccionTotal\n",
    "df1['prediccion']=prediccion1\n",
    "df2['prediccion']=prediccion2\n",
    "df3['prediccion']=prediccion3\n",
    "df4['prediccion']=prediccion4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=atinar(test)\n",
    "df1=atinar(df1)\n",
    "df2=atinar(df2)\n",
    "df3=atinar(df3)\n",
    "df4=atinar(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcenAciertoTotal=((test['acierto'].values.sum())/len(test))*100\n",
    "porcenAciertoMod1=((df1['acierto'].values.sum())/len(df1))*100\n",
    "porcenAciertoMod2=((df2['acierto'].values.sum())/len(df2))*100\n",
    "porcenAciertoMod3=((df3['acierto'].values.sum())/len(df3))*100\n",
    "porcenAciertoMod4=((df4['acierto'].values.sum())/len(df4))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(porcenAciertoTotal)\n",
    "print(porcenAciertoMod1)\n",
    "print(porcenAciertoMod2)\n",
    "print(porcenAciertoMod3)\n",
    "print(porcenAciertoMod4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizConfusioTotal=confusio(test)\n",
    "matrizConfusio1=confusio(df1)\n",
    "matrizConfusio2=confusio(df2)\n",
    "matrizConfusio3=confusio(df3)\n",
    "matrizConfusio4=confusio(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrizConfusioTotal)\n",
    "print(matrizConfusio1)\n",
    "print(matrizConfusio2)\n",
    "print(matrizConfusio3)\n",
    "print(matrizConfusio4)"
   ]
  }
 ]
}